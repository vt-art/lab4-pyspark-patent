{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCI 4253 / 5253 - Lab #4 - Patent Problem with Spark DataFrames\n",
    "<div>\n",
    " <h2> CSCI 4283 / 5253 \n",
    "  <IMG SRC=\"https://www.colorado.edu/cs/profiles/express/themes/cuspirit/logo.png\" WIDTH=50 ALIGN=\"right\"/> </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This [Spark cheatsheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/PySpark_SQL_Cheat_Sheet_Python.pdf) is useful as is [this reference on doing joins in Spark dataframe](http://www.learnbymarketing.com/1100/pyspark-joins-by-example/).\n",
    "\n",
    "The [DataBricks company has one of the better reference manuals for PySpark](https://docs.databricks.com/spark/latest/dataframes-datasets/index.html) -- they show you how to perform numerous common data operations such as joins, aggregation operations following `groupBy` and the like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following aggregation functions may be useful -- [these can be used to aggregate results of `groupby` operations](https://docs.databricks.com/spark/latest/dataframes-datasets/introduction-to-dataframes-python.html#example-aggregations-using-agg-and-countdistinct). More documentation is at the [PySpark SQL Functions manual](https://spark.apache.org/docs/2.3.0/api/python/pyspark.sql.html#module-pyspark.sql.functions). Feel free to use other functions from that library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Added length and trim to address missing rows. Added coalesce for join\n",
    "from pyspark.sql.functions import col, count, countDistinct, length, trim, lit,coalesce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Lab4-Dataframe\") \\\n",
    "    .master(\"local[*]\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the citations and patents data and check that the data makes sense. Note that unlike in the RDD solution, the data is automatically inferred to be Integer() types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "citations = spark.read.load('cite75_99.txt.gz',\n",
    "            format=\"csv\", sep=\",\", header=True,\n",
    "            compression=\"gzip\",\n",
    "            inferSchema=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "| CITING|  CITED|\n",
      "+-------+-------+\n",
      "|3858241| 956203|\n",
      "|3858241|1324234|\n",
      "|3858241|3398406|\n",
      "|3858241|3557384|\n",
      "|3858241|3634889|\n",
      "+-------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "citations.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "patents = spark.read.load('apat63_99.txt.gz',\n",
    "            format=\"csv\", sep=\",\", header=True,\n",
    "            compression=\"gzip\",\n",
    "            inferSchema=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+\n",
      "| PATENT|GYEAR|GDATE|APPYEAR|COUNTRY|POSTATE|ASSIGNEE|ASSCODE|CLAIMS|NCLASS|CAT|SUBCAT|CMADE|CRECEIVE|RATIOCIT|GENERAL|ORIGINAL|FWDAPLAG|BCKGTLAG|SELFCTUB|SELFCTLB|SECDUPBD|SECDLWBD|\n",
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+\n",
      "|3070801| 1963| 1096|   NULL|     BE|   NULL|    NULL|      1|  NULL|   269|  6|    69| NULL|       1|    NULL|    0.0|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|\n",
      "|3070802| 1963| 1096|   NULL|     US|     TX|    NULL|      1|  NULL|     2|  6|    63| NULL|       0|    NULL|   NULL|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|\n",
      "|3070803| 1963| 1096|   NULL|     US|     IL|    NULL|      1|  NULL|     2|  6|    63| NULL|       9|    NULL| 0.3704|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|\n",
      "|3070804| 1963| 1096|   NULL|     US|     OH|    NULL|      1|  NULL|     2|  6|    63| NULL|       3|    NULL| 0.6667|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|\n",
      "|3070805| 1963| 1096|   NULL|     US|     CA|    NULL|      1|  NULL|     2|  6|    63| NULL|       1|    NULL|    0.0|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|    NULL|\n",
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "patents.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach\n",
    "1) Create aliases for the citations DataFrame and two copies for the patents DataFrame where one represents the CITED patent and the other represents the CITING patent. This allows the patent DataFrame to be joined twice so that we can pull off the CITED state and the CITING state.\n",
    "2) Calculate the co-state citation count\n",
    "- Join the CITED patent from the citations DataFrame with the patents table on CITED.\n",
    "- Join the CITING patent from the citations DataFrame with the patents table on CITING.\n",
    "- Keep records where the cited state is equal to the citing state, so long as neither cited state nor citing state are missing.\n",
    "\n",
    "3) Group the filtered results by the citing patent using `.groupBy()`.\n",
    "4) Aggregate the grouped records using `.count()` to calculate the number of co-state citations per citing patent to `CO_CITED_COUNT`.\n",
    "5) Left join the co-state citation count with the full patent DataFrame. Include those with zero co-state citations. Missing counts are replaced with zero using `coalesce()`.\n",
    "6) Order by descending co-state count using `orderBy()` and `.desc`.\n",
    "7) Display the top ten patents using `limit()` and `.show()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+--------------+\n",
      "|PATENT |GYEAR|GDATE|APPYEAR|COUNTRY|POSTATE|ASSIGNEE|ASSCODE|CLAIMS|NCLASS|CAT|SUBCAT|CMADE|CRECEIVE|RATIOCIT|GENERAL|ORIGINAL|FWDAPLAG|BCKGTLAG|SELFCTUB|SELFCTLB|SECDUPBD|SECDLWBD|CO_CITED_COUNT|\n",
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+--------------+\n",
      "|5959466|1999 |14515|1997   |US     |CA     |5310    |2      |NULL  |326   |4  |46    |159  |0       |1.0     |NULL   |0.6186  |NULL    |4.8868  |0.0455  |0.044   |NULL    |NULL    |125           |\n",
      "|5983822|1999 |14564|1998   |US     |TX     |569900  |2      |NULL  |114   |5  |55    |200  |0       |0.995   |NULL   |0.7201  |NULL    |12.45   |0.0     |0.0     |NULL    |NULL    |103           |\n",
      "|6008204|1999 |14606|1998   |US     |CA     |749584  |2      |NULL  |514   |3  |31    |121  |0       |1.0     |NULL   |0.7415  |NULL    |5.0     |0.0085  |0.0083  |NULL    |NULL    |100           |\n",
      "|5952345|1999 |14501|1997   |US     |CA     |749584  |2      |NULL  |514   |3  |31    |118  |0       |1.0     |NULL   |0.7442  |NULL    |5.1102  |0.0     |0.0     |NULL    |NULL    |98            |\n",
      "|5958954|1999 |14515|1997   |US     |CA     |749584  |2      |NULL  |514   |3  |31    |116  |0       |1.0     |NULL   |0.7397  |NULL    |5.181   |0.0     |0.0     |NULL    |NULL    |96            |\n",
      "|5998655|1999 |14585|1998   |US     |CA     |NULL    |1      |NULL  |560   |1  |14    |114  |0       |1.0     |NULL   |0.7387  |NULL    |5.1667  |NULL    |NULL    |NULL    |NULL    |96            |\n",
      "|5936426|1999 |14466|1997   |US     |CA     |5310    |2      |NULL  |326   |4  |46    |178  |0       |1.0     |NULL   |0.58    |NULL    |11.2303 |0.0765  |0.073   |NULL    |NULL    |94            |\n",
      "|5951547|1999 |14501|1997   |US     |CA     |733846  |2      |NULL  |606   |3  |32    |242  |0       |1.0     |NULL   |0.7382  |NULL    |8.3471  |0.0     |0.0     |NULL    |NULL    |90            |\n",
      "|5913855|1999 |14417|1997   |US     |CA     |733846  |2      |NULL  |606   |3  |32    |242  |0       |1.0     |NULL   |0.7403  |NULL    |8.3595  |0.0     |0.0     |NULL    |NULL    |90            |\n",
      "|5978329|1999 |14550|1995   |US     |CA     |148925  |2      |NULL  |369   |2  |24    |145  |0       |1.0     |NULL   |0.5449  |NULL    |12.9241 |0.4196  |0.4138  |NULL    |NULL    |90            |\n",
      "+-------+-----+-----+-------+-------+-------+--------+-------+------+------+---+------+-----+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# aliases\n",
    "c = citations.alias(\"c\")\n",
    "p_cited  = patents.alias(\"p_cited\")\n",
    "p_citing = patents.alias(\"p_citing\")\n",
    "\n",
    "co_state_counts = (\n",
    "    c.join(p_cited,  col(\"c.CITED\")  == col(\"p_cited.PATENT\"),  \"inner\")\n",
    "     .join(p_citing, col(\"c.CITING\") == col(\"p_citing.PATENT\"), \"inner\")\n",
    "     .where(\n",
    "         (col(\"p_cited.POSTATE\") == col(\"p_citing.POSTATE\")) &\n",
    "         (length(trim(col(\"p_cited.POSTATE\")))  > 0) &\n",
    "         (length(trim(col(\"p_citing.POSTATE\"))) > 0)\n",
    "     )\n",
    "     .groupBy(col(\"c.CITING\").alias(\"PATENT\"))\n",
    "     .agg(count(lit(1)).alias(\"CO_CITED_COUNT\"))   # equivalent to COUNT(*)\n",
    ")\n",
    "\n",
    "result_df = (\n",
    "    patents.alias(\"p\")\n",
    "      .join(co_state_counts.alias(\"cs\"), col(\"p.PATENT\") == col(\"cs.PATENT\"), \"left\")\n",
    "      .select(\n",
    "          \"p.*\",\n",
    "          coalesce(col(\"cs.CO_CITED_COUNT\"), lit(0)).alias(\"CO_CITED_COUNT\")\n",
    "      )\n",
    "      .orderBy(col(\"CO_CITED_COUNT\").desc())\n",
    "      .limit(10)\n",
    ")\n",
    "\n",
    "result_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
